version: '3.8'

services:
  fastapi-blog:
    build: .
    ports:
      - "7999:7999"
    environment:
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./checkpoints:/app/checkpoints
      - ./storage:/app/storage
    restart: unless-stopped
    depends_on: []
    # Using network_mode: host means the container uses the host's network
    # So it can access Ollama on localhost:11434 directly 